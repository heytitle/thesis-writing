
@article{ArrasWhatRelevantText2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.07843},
  primaryClass = {cs, stat},
  title = {"{{What}} Is {{Relevant}} in a {{Text Document}}?": {{An Interpretable Machine Learning Approach}}},
  url = {http://arxiv.org/abs/1612.07843},
  shorttitle = {"{{What}} Is {{Relevant}} in a {{Text Document}}?},
  abstract = {Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text's category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.},
  urldate = {2017-07-19},
  date = {2016-12-22},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Learning,Statistics - Machine Learning},
  author = {Arras, Leila and Horn, Franziska and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  file = {/Users/heytitle/Zotero/storage/7AKZETAH/Arras et al. - 2016 - What is Relevant in a Text Document An Interpr.pdf;/Users/heytitle/Zotero/storage/ZUWJYIHN/1612.html},
  year = {2016}
}

@article{MontavonExplainingnonlinearclassification2017,
  title = {Explaining Nonlinear Classification Decisions with Deep {{Taylor}} Decomposition},
  volume = {65},
  issn = {0031-3203},
  url = {http://www.sciencedirect.com/science/article/pii/S0031320316303582},
  doi = {10.1016/j.patcog.2016.11.008},
  abstract = {Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  urldate = {2017-07-23},
  date = {2017-05-01},
  pages = {211--222},
  keywords = {Deep neural networks,Heatmapping,Image recognition,Relevance propagation,Taylor decomposition},
  author = {Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  file = {/Users/heytitle/Zotero/storage/ZRJN2CBI/S0031320316303582.html},
  journal = {Pattern Recognition},
  year = {May 1, 2017}
}

@article{MontavonMethodsInterpretingUnderstanding2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07979},
  primaryClass = {cs, stat},
  title = {Methods for {{Interpreting}} and {{Understanding Deep Neural Networks}}},
  url = {http://arxiv.org/abs/1706.07979},
  abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. It introduces some recently proposed techniques of interpretation, along with theory, tricks and recommendations, to make most efficient use of these techniques on real data. It also discusses a number of practical applications.},
  urldate = {2017-07-24},
  date = {2017-06-24},
  keywords = {Computer Science - Learning,Statistics - Machine Learning},
  author = {Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  file = {/Users/heytitle/Zotero/storage/DE3B5ZN9/Montavon et al. - 2017 - Methods for Interpreting and Understanding Deep Ne.pdf;/Users/heytitle/Zotero/storage/LVET2A5I/1706.html},
  year = {2017}
}

@article{KindermansPatternNetPatternLRPImproving2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.05598},
  primaryClass = {cs, stat},
  title = {{{PatternNet}} and {{PatternLRP}} -- {{Improving}} the Interpretability of Neural Networks},
  url = {http://arxiv.org/abs/1705.05598},
  abstract = {Deep learning has significantly advanced the state of the art in machine learning. However, neural networks are often considered black boxes. There is significant effort to develop techniques that explain a classifier's decisions. Although some of these approaches have resulted in compelling visualisations, there is a lack of theory of what is actually explained. Here we present an analysis of these methods and formulate a quality criterion for explanation methods. On this ground, we propose an improved method that may serve as an extension for existing back-projection and decomposition techniques.},
  urldate = {2017-07-24},
  date = {2017-05-16},
  keywords = {Computer Science - Learning,Statistics - Machine Learning},
  author = {Kindermans, Pieter-Jan and Sch{\"u}tt, Kristof T. and Alber, Maximilian and M{\"u}ller, Klaus-Robert and D{\"a}hne, Sven},
  file = {/Users/heytitle/Zotero/storage/C3AJYV3A/Kindermans et al. - 2017 - PatternNet and PatternLRP -- Improving the interpr.pdf;/Users/heytitle/Zotero/storage/PQPY6K78/1705.html},
  year = {2017}
}

@article{WieschollekLearningBlindMotion2017,
  title = {Learning {{Blind Motion Deblurring}}},
  url = {http://arxiv.org/abs/1708.04208v1},
  abstract = {As handheld video cameras are now commonplace and available in every
smartphone, images and videos can be recorded almost everywhere at anytime.
However, taking a quick shot frequently yields a blurry result due to unwanted
camera shake during recording or moving objects in the scene. Removing these
artifacts from the blurry recordings is a highly ill-posed problem as neither
the sharp image nor the motion blur kernel is known. Propagating information
between multiple consecutive blurry observations can help restore the desired
sharp image or video. Solutions for blind deconvolution based on neural
networks rely on a massive amount of ground-truth data which is hard to
acquire. In this work, we propose an efficient approach to produce a
significant amount of realistic training data and introduce a novel recurrent
network architecture to deblur frames taking temporal information into account,
which can efficiently handle arbitrary spatial and temporal input sizes. We
demonstrate the versatility of our approach in a comprehensive comparison on a
number of challening real-world examples.},
  journaltitle = {arXiv:1708.04208v1 [cs]},
  shortjournal = {ArXiv170804208v1 Cs},
  date = {2017-08-14},
  author = {Wieschollek, Patrick and Hirsch, Michael and Sch{\"o}lkopf, Bernhard and Lensch, Hendrik P. A.},
  journal = {arXiv:1708.04208v1 [cs]},
  year = {8/14/2017}
}

@article{PhanAudioSceneClassification2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.04770},
  primaryClass = {cs},
  title = {Audio {{Scene Classification}} with {{Deep Recurrent Neural Networks}}},
  url = {http://arxiv.org/abs/1703.04770},
  abstract = {We introduce in this work an efficient approach for audio scene classification using deep recurrent neural networks. An audio scene is firstly transformed into a sequence of high-level label tree embedding feature vectors. The vector sequence is then divided into multiple subsequences on which a deep GRU-based recurrent neural network is trained for sequence-to-label classification. The global predicted label for the entire sequence is finally obtained via aggregation of subsequence classification outputs. We will show that our approach obtains an F1-score of 97.7\% on the LITIS Rouen dataset, which is the largest dataset publicly available for the task. Compared to the best previously reported result on the dataset, our approach is able to reduce the relative classification error by 35.3\%.},
  urldate = {2017-09-06},
  date = {2017-03-14},
  keywords = {Computer Science - Learning,Computer Science - Sound},
  author = {Phan, Huy and Koch, Philipp and Katzberg, Fabrice and Maass, Marco and Mazur, Radoslaw and Mertins, Alfred},
  file = {/Users/heytitle/Zotero/storage/YKJIFNU4/Phan et al. - 2017 - Audio Scene Classification with Deep Recurrent Neu.pdf;/Users/heytitle/Zotero/storage/UDEGEVUL/1703.html},
  year = {2017}
}

@article{ShahriariTakingHumanOut2016,
  title = {Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian Optimization}}},
  volume = {104},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2015.2494218},
  shorttitle = {Taking the {{Human Out}} of the {{Loop}}},
  abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  number = {1},
  journaltitle = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  date = {2016-01},
  pages = {148--175},
  keywords = {Big data,Bayes methods,Bayesian optimization,Big Data,Big data application,decision making,Decision making,design of experiments,Design of experiments,Genomes,genomic medicine,human productivity,large-scale heterogeneous computing,Linear programming,massive complex software system,optimisation,optimization,Optimization,product quality,response surface methodology,Statistical analysis,statistical learning,storage allocation,storage architecture},
  author = {Shahriari, B. and Swersky, K. and Wang, Z. and Adams, R. P. and de Freitas, N.},
  file = {/Users/heytitle/Zotero/storage/HHWVCX3I/7352306.html},
  journal = {Proceedings of the IEEE},
  year = {January 2016}
}

@article{XiaoFashionMNISTNovelImage2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1708.07747},
  primaryClass = {cs, stat},
  title = {Fashion-{{MNIST}}: A {{Novel Image Dataset}} for {{Benchmarking Machine Learning Algorithms}}},
  url = {http://arxiv.org/abs/1708.07747},
  shorttitle = {Fashion-{{MNIST}}},
  abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
  urldate = {2017-12-28},
  date = {2017-08-25},
  keywords = {Computer Science - Learning,Statistics - Machine Learning,Computer Science - Computer Vision and Pattern Recognition},
  author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  file = {/Users/heytitle/Zotero/storage/8Y9MAPE9/Xiao et al. - 2017 - Fashion-MNIST a Novel Image Dataset for Benchmark.pdf;/Users/heytitle/Zotero/storage/9MPKQEQV/1708.html},
  year = {2017}
}

@article{LeCunMNISThandwrittendigit2010,
  title = {{{MNIST}} Handwritten Digit Database},
  url = {http://yann.lecun.com/exdb/mnist/},
  urldate = {2016-01-14},
  date = {2010},
  keywords = {MSc _checked character_recognition mnist network neural},
  author = {LeCun, Yann and Cortes, Corinna},
  year = {2010}
}

@article{ZagoruykoWideResidualNetworks2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.07146},
  primaryClass = {cs},
  title = {Wide {{Residual Networks}}},
  url = {http://arxiv.org/abs/1605.07146},
  abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https://github.com/szagoruyko/wide-residual-networks},
  urldate = {2017-12-29},
  date = {2016-05-23},
  keywords = {Computer Science - Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Computer Vision and Pattern Recognition},
  author = {Zagoruyko, Sergey and Komodakis, Nikos},
  file = {/Users/heytitle/Zotero/storage/GQ8BZUF6/Zagoruyko and Komodakis - 2016 - Wide Residual Networks.pdf;/Users/heytitle/Zotero/storage/ASDJ8RUP/1605.html},
  year = {2016}
}

@inproceedings{KingmaAdamMethodStochastic2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.6980},
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  url = {http://arxiv.org/abs/1412.6980},
  shorttitle = {Adam},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  booktitle = {Proceedings of the 3rd {{International Conference}} on {{Learning Representations}} ({{ICLR}})},
  urldate = {2017-12-29},
  date = {2014-12-22},
  keywords = {Computer Science - Learning},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  file = {/Users/heytitle/Zotero/storage/VZXMDASB/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf;/Users/heytitle/Zotero/storage/TSUEKSFG/1412.html},
  journal = {Proceedings of the 3rd International Conference on Learning Representations (ICLR)},
  year = {2014}
}

@inproceedings{ErhanVisualizingHigherLayerFeatures2009,
  title = {Visualizing {{Higher}}-{{Layer Features}} of a {{Deep Network}}},
  abstract = {Deep architectures have demonstrated state-of-the-art results in a variety of settings, especially with vision datasets. Beyond the model definitions and the quantitative analyses, there is a need for qualitative comparisons of the solutions learned by various deep architectures. The goal of this paper is to find good qualitative interpretations of high level features represented by such models. To this end, we contrast and compare several techniques applied on Stacked Denoising Autoencoders and Deep Belief Networks, trained on several vision datasets. We show that, perhaps counter-intuitively, such interpretation is possible at the unit level, that it is simple to accomplish and that the results are consistent across various techniques. We hope that such techniques will allow researchers in deep architectures to understand more of how and why deep architectures work.},
  date = {2009},
  author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron C. and Vincent, Pascal},
  file = {/Users/heytitle/Zotero/storage/TJT9A3LN/Erhan et al. - 2009 - Visualizing Higher-Layer Features of a Deep Networ.pdf},
  year = {2009}
}

@article{AbadiTensorFlowLargeScaleMachine2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.04467},
  primaryClass = {cs},
  title = {{{TensorFlow}}: {{Large}}-{{Scale Machine Learning}} on {{Heterogeneous Distributed Systems}}},
  url = {http://arxiv.org/abs/1603.04467},
  shorttitle = {{{TensorFlow}}},
  abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
  urldate = {2018-01-03},
  date = {2016-03-14},
  keywords = {Computer Science - Learning,Computer Science - Distributed; Parallel; and Cluster Computing},
  author = {Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  file = {/Users/heytitle/Zotero/storage/FQVBI7V4/Abadi et al. - 2016 - TensorFlow Large-Scale Machine Learning on Hetero.pdf;/Users/heytitle/Zotero/storage/C72L7DTQ/1603.html},
  year = {2016}
}

@article{BachPixelWiseExplanationsNonLinear2015,
  title = {On {{Pixel}}-{{Wise Explanations}} for {{Non}}-{{Linear Classifier Decisions}} by {{Layer}}-{{Wise Relevance Propagation}}},
  volume = {10},
  issn = {1932-6203},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4498753/},
  doi = {10.1371/journal.pone.0130140},
  abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
  number = {7},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  urldate = {2018-01-04},
  date = {2015-07-10},
  author = {Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  file = {/Users/heytitle/Zotero/storage/RU4CWF93/Bach et al. - 2015 - On Pixel-Wise Explanations for Non-Linear Classifi.pdf},
  eprinttype = {pmid},
  eprint = {26161953},
  pmcid = {PMC4498753},
  journal = {PLoS ONE},
  year = {2015}
}

@article{TalathiImprovingperformancerecurrent2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.03771},
  primaryClass = {cs},
  title = {Improving Performance of Recurrent Neural Network with Relu Nonlinearity},
  url = {http://arxiv.org/abs/1511.03771},
  abstract = {In recent years significant progress has been made in successfully training recurrent neural networks (RNNs) on sequence learning problems involving long range temporal dependencies. The progress has been made on three fronts: (a) Algorithmic improvements involving sophisticated optimization techniques, (b) network design involving complex hidden layer nodes and specialized recurrent layer connections and (c) weight initialization methods. In this paper, we focus on recently proposed weight initialization with identity matrix for the recurrent weights in a RNN. This initialization is specifically proposed for hidden nodes with Rectified Linear Unit (ReLU) non linearity. We offer a simple dynamical systems perspective on weight initialization process, which allows us to propose a modified weight initialization strategy. We show that this initialization technique leads to successfully training RNNs composed of ReLUs. We demonstrate that our proposal produces comparable or better solution for three toy problems involving long range temporal structure: the addition problem, the multiplication problem and the MNIST classification problem using sequence of pixels. In addition, we present results for a benchmark action recognition problem.},
  urldate = {2018-01-06},
  date = {2015-11-11},
  keywords = {Computer Science - Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Talathi, Sachin S. and Vartak, Aniket},
  file = {/Users/heytitle/Zotero/storage/UWMP5FI5/Talathi and Vartak - 2015 - Improving performance of recurrent neural network .pdf;/Users/heytitle/Zotero/storage/G2ZVPXJ9/1511.html},
  year = {2015}
}

@article{BachAnalyzingClassifiersFisher2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.00172},
  primaryClass = {cs},
  title = {Analyzing {{Classifiers}}: {{Fisher Vectors}} and {{Deep Neural Networks}}},
  url = {http://arxiv.org/abs/1512.00172},
  shorttitle = {Analyzing {{Classifiers}}},
  abstract = {Fisher Vector classifiers and Deep Neural Networks (DNNs) are popular and successful algorithms for solving image classification problems. However, both are generally considered `black box' predictors as the non-linear transformations involved have so far prevented transparent and interpretable reasoning. Recently, a principled technique, Layer-wise Relevance Propagation (LRP), has been developed in order to better comprehend the inherent structured reasoning of complex nonlinear classification models such as Bag of Feature models or DNNs. In this paper we (1) extend the LRP framework also for Fisher Vector classifiers and then use it as analysis tool to (2) quantify the importance of context for classification, (3) qualitatively compare DNNs against FV classifiers in terms of important image regions and (4) detect potential flaws and biases in data. All experiments are performed on the PASCAL VOC 2007 data set.},
  urldate = {2018-01-07},
  date = {2015-12-01},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  file = {/Users/heytitle/Zotero/storage/THNBMRDD/Bach et al. - 2015 - Analyzing Classifiers Fisher Vectors and Deep Neu.pdf;/Users/heytitle/Zotero/storage/QCG7GMKG/1512.html},
  year = {2015}
}

@article{GuntukuUnderstandingDeepRepresentations2016,
  title = {Understanding {{Deep Representations Learned}} in {{Modeling Users Likes}}},
  volume = {25},
  issn = {1057-7149},
  doi = {10.1109/TIP.2016.2576278},
  abstract = {Automatically understanding and discriminating different users' liking for an image is a challenging problem. This is because the relationship between image features (even semantic ones extracted by existing tools, viz., faces, objects, and so on) and users' likes is non-linear, influenced by several subtle factors. This paper presents a deep bi-modal knowledge representation of images based on their visual content and associated tags (text). A mapping step between the different levels of visual and textual representations allows for the transfer of semantic knowledge between the two modalities. Feature selection is applied before learning deep representation to identify the important features for a user to like an image. The proposed representation is shown to be effective in discriminating users based on images they like and also in recommending images that a given user likes, outperforming the state-of-the-art feature representations by 15 \%-20\%. Beyond this test-set performance, an attempt is made to qualitatively understand the representations learned by the deep architecture used to model user likes.},
  number = {8},
  journaltitle = {IEEE Transactions on Image Processing},
  shortjournal = {IEEE Trans. Image Process.},
  date = {2016-08},
  pages = {3762--3774},
  keywords = {learning (artificial intelligence),automatic user liking discriminating,automatic user liking understanding,Clutter,Context,Context modeling,deep bimodal image knowledge representation,deep representation learning,Deep representations,Deep Representations,feature extraction,Feature extraction,feature representations,feature selection,image features,image recommendation,Image Recommendation,image representation,image retrieval,knowledge representation,semantic knowledge transfer,semantic structures,Semantic Structures,Semantics,tags,textual representations,user likes,User Likes,user liking modeling,visual content,visual representations,Visualization},
  author = {Guntuku, S. C. and Zhou, J. T. and Roy, S. and Lin, W. and Tsang, I. W.},
  file = {/Users/heytitle/Zotero/storage/R427XJJ2/7484658.html},
  journal = {IEEE Transactions on Image Processing},
  year = {August 2016}
}

@online{UnderstandingRepresentationsLearned,
  title = {Understanding {{Representations Learned}} in {{Deep Architectures}} - {{LISA}} - {{Publications}} - {{Aigaion}} 2.0},
  url = {http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/473},
  urldate = {2018-01-07}
}

@report{ErhanUnderstandingRepresentationsLearned2010,
  title = {Understanding {{Representations Learned}} in {{Deep Architectures}}},
  abstract = {Deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with vision datasets. Deep learning algorithms are based on learning several levels of representation of the input. Beyond test-set performance, there is a need for qualitative comparisons of the solutions learned by various deep architectures, focused on those learned representations. One of the goals of our research is to improve tools for finding good qualitative interpretations of high level features learned by such models. We also seek to gain insight into the invariances learned by deep networks. To this end, we contrast and compare several techniques for finding such interpretations. We applied our techniques on Stacked Denoising Auto-Encoders and Deep Belief Networks, trained on several vision datasets. We show that consistent filter-like interpretation is possible and simple to accomplish at the unit level. The tools developed make it possible to analyze deep models in more depth and accomplish the tracing of invariance manifolds for each of the hidden units. We hope that such techniques will allow researchers in deep architectures to understand more of how and why deep architectures work.},
  number = {1355},
  institution = {{Universit{\'e} de Montr{\'e}al/DIRO}},
  date = {2010-10},
  author = {Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua},
  year = {October 2010}
}

@article{SzegedyGoingDeeperConvolutions2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.4842},
  primaryClass = {cs},
  title = {Going {{Deeper}} with {{Convolutions}}},
  url = {http://arxiv.org/abs/1409.4842},
  abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  urldate = {2018-01-07},
  date = {2014-09-16},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  file = {/Users/heytitle/Zotero/storage/IWNR9Z5N/1409.html},
  year = {2014}
}

@article{JiaCaffeConvolutionalArchitecture2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1408.5093},
  primaryClass = {cs},
  title = {Caffe: {{Convolutional Architecture}} for {{Fast Feature Embedding}}},
  url = {http://arxiv.org/abs/1408.5093},
  shorttitle = {Caffe},
  abstract = {Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (\$$\backslash$approx\$ 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.},
  urldate = {2018-01-07},
  date = {2014-06-20},
  keywords = {Computer Science - Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Computer Vision and Pattern Recognition},
  author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  file = {/Users/heytitle/Zotero/storage/I6BSYTS6/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature.pdf;/Users/heytitle/Zotero/storage/UA287H2W/1408.html},
  year = {2014}
}

@inproceedings{BinderLayerWiseRelevancePropagation2016,
  langid = {english},
  title = {Layer-{{Wise Relevance Propagation}} for {{Neural Networks}} with {{Local Renormalization Layers}}},
  isbn = {978-3-319-44780-3 978-3-319-44781-0},
  url = {https://link.springer.com/chapter/10.1007/978-3-319-44781-0_8},
  doi = {10.1007/978-3-319-44781-0_8},
  abstract = {Layer-wise relevance propagation is a framework which allows to decompose the prediction of a deep neural network computed over a sample, e.g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, which is a very common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR-10, Imagenet and MIT Places datasets.},
  eventtitle = {International {{Conference}} on {{Artificial Neural Networks}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} \textendash{} {{ICANN}} 2016},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer, Cham}},
  urldate = {2018-01-07},
  date = {2016-09-06},
  pages = {63--71},
  author = {Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  file = {/Users/heytitle/Zotero/storage/3ALFZF4Z/978-3-319-44781-0_8.html},
  journal = {Artificial Neural Networks and Machine Learning â€“ ICANN 2016},
  year = {2016/09/06}
}

@article{GreffLSTMsearchspace2017,
  title = {{{LSTM}}: {{A}} Search Space Odyssey},
  journaltitle = {IEEE transactions on neural networks and learning systems},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  date = {2017},
  author = {Greff, Klaus and Srivastava, Rupesh K and Koutn{\'\i}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"u}rgen},
  journal = {IEEE transactions on neural networks and learning systems},
  year = {2017}
}

@article{SundararajanAxiomaticAttributionDeep2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.01365},
  primaryClass = {cs},
  title = {Axiomatic {{Attribution}} for {{Deep Networks}}},
  url = {http://arxiv.org/abs/1703.01365},
  abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms---Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
  urldate = {2018-01-17},
  date = {2017-03-03},
  keywords = {Computer Science - Learning},
  author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  file = {/Users/heytitle/Zotero/storage/RDGU37H2/Sundararajan et al. - 2017 - Axiomatic Attribution for Deep Networks.pdf;/Users/heytitle/Zotero/storage/X4RHU78K/1703.html},
  year = {2017}
}

@article{ArrasExplainingRecurrentNeural2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07206},
  primaryClass = {cs, stat},
  title = {Explaining {{Recurrent Neural Network Predictions}} in {{Sentiment Analysis}}},
  url = {http://arxiv.org/abs/1706.07206},
  abstract = {Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to recurrent neural networks. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work.},
  urldate = {2018-02-11},
  date = {2017-06-22},
  keywords = {Computer Science - Computation and Language,Statistics - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Artificial Intelligence,for-1st-paper},
  author = {Arras, Leila and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  file = {/Users/heytitle/Zotero/storage/L79FLFIS/Arras et al. - 2017 - Explaining Recurrent Neural Network Predictions in.pdf;/Users/heytitle/Zotero/storage/AASM8MQA/1706.html},
  year = {2017}
}

@article{SimonyanDeepConvolutionalNetworks2013,
  title = {Deep {{Inside Convolutional Networks}}: {{Visualising Image Classification Models}} and {{Saliency Maps}}},
  volume = {abs/1312.6034},
  url = {http://arxiv.org/abs/1312.6034},
  journaltitle = {CoRR},
  date = {2013},
  author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal = {CoRR},
  year = {2013}
}

@article{SpringenbergStrivingSimplicityAll2014e,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.6806},
  title = {Striving for {{Simplicity}}: {{The All Convolutional Net}}},
  volume = {abs/1412.6806},
  url = {http://arxiv.org/abs/1412.6806},
  journaltitle = {CoRR},
  date = {2014},
  author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin A.},
  biburl = {https://dblp.org/rec/bib/journals/corr/SpringenbergDBR14},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  journal = {CoRR},
  year = {2014}
}

@inproceedings{BachAnalyzingclassifiersFisher2016,
  title = {Analyzing Classifiers: {{Fisher}} Vectors and Deep Neural Networks},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  date = {2016},
  pages = {2912--2920},
  author = {Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Muller, Klaus-Robert and Samek, Wojciech},
  journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year = {2016}
}

@article{TielemanLectureRmsPropDivide2012,
  title = {Lecture 6.5---{{RmsProp}}: {{Divide}} the Gradient by a Running Average of Its Recent Magnitude},
  date = {2012},
  author = {Tieleman, T. and Hinton, G.},
  howpublished = {COURSERA: Neural Networks for Machine Learning},
  year = {2012}
}

@article{ZeilerADADELTAAdaptiveLearning2012,
  title = {{{ADADELTA}}: {{An Adaptive Learning Rate Method}}},
  volume = {abs/1212.5701},
  journaltitle = {CoRR},
  date = {2012},
  author = {Zeiler, Matthew D.},
  ee = {http://arxiv.org/abs/1212.5701},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  journal = {CoRR},
  year = {2012}
}

@article{ZeilerVisualizingUnderstandingConvolutional2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1311.2901},
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  volume = {abs/1311.2901},
  url = {http://arxiv.org/abs/1311.2901},
  journaltitle = {CoRR},
  date = {2013},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  biburl = {https://dblp.org/rec/bib/journals/corr/ZeilerF13},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  journal = {CoRR},
  year = {2013}
}

@article{SimonyanVeryDeepConvolutional2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.1556},
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  volume = {abs/1409.1556},
  url = {http://arxiv.org/abs/1409.1556},
  journaltitle = {CoRR},
  date = {2014},
  author = {Simonyan, Karen and Zisserman, Andrew},
  biburl = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  journal = {CoRR},
  year = {2014}
}

@article{HeDeepResidualLearning2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  volume = {abs/1512.03385},
  url = {http://arxiv.org/abs/1512.03385},
  journaltitle = {CoRR},
  date = {2015},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  biburl = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  journal = {CoRR},
  year = {2015}
}

@inproceedings{LeCunGradientBasedLearningApplied2001,
  title = {Gradient-{{Based Learning Applied}} to {{Document Recognition}}},
  booktitle = {Intelligent {{Signal Processing}}},
  publisher = {{IEEE Press}},
  date = {2001},
  pages = {306--351},
  author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  original = {orig/lecun-01a.ps.gz},
  editors = {Haykin, S. and Kosko, B.},
  journal = {Intelligent Signal Processing},
  year = {2001}
}

@incollection{KrizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  booktitle = {Advances in {{Neural Information Processing Systems}} 25},
  publisher = {{Curran Associates, Inc.}},
  date = {2012},
  pages = {1097--1105},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  journal = {Advances in Neural Information Processing Systems 25},
  year = {2012}
}

@article{PascanuUnderstandingexplodinggradient2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1211.5063},
  title = {Understanding the Exploding Gradient Problem},
  volume = {abs/1211.5063},
  url = {http://arxiv.org/abs/1211.5063},
  journaltitle = {CoRR},
  date = {2012},
  author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1211-5063},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  journal = {CoRR},
  year = {2012}
}

@article{HochreiterLongshorttermmemory1997,
  title = {Long Short-Term Memory},
  volume = {9},
  number = {8},
  journaltitle = {Neural computation},
  shortjournal = {Neural Comput.},
  date = {1997},
  pages = {1735--1780},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  publisher = {{MIT Press}},
  journal = {Neural computation},
  year = {1997}
}

@inproceedings{ChoLearningPhraseRepresentations2014a,
  location = {{Doha, Qatar}},
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder}}--{{Decoder}} for {{Statistical Machine Translation}}},
  url = {http://www.aclweb.org/anthology/D14-1179},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  publisher = {{Association for Computational Linguistics}},
  date = {2014-10},
  pages = {1724--1734},
  author = {Cho, Kyunghyun and van Merri{\"e}nboer, Bart and G{\"u}l{\c c}ehre, {\c C}a{\u g}lar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  options = {useprefix=true},
  journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2014}
}

@article{Jozefowiczempiricalexplorationrecurrent2015a,
  title = {An Empirical Exploration of Recurrent Network Architectures},
  journaltitle = {Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  date = {2015},
  author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
  journal = {Journal of Machine Learning Research},
  year = {2015}
}

@incollection{GalTheoreticallyGroundedApplication2016,
  title = {A {{Theoretically Grounded Application}} of {{Dropout}} in {{Recurrent Neural Networks}}},
  url = {http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  date = {2016},
  pages = {1019--1027},
  author = {Gal, Yarin and Ghahramani, Zoubin},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  journal = {Advances in Neural Information Processing Systems 29},
  year = {2016}
}

@inproceedings{LeeConvolutionalDeepBelief2009,
  location = {{Montreal, Quebec, Canada}},
  title = {Convolutional {{Deep Belief Networks}} for {{Scalable Unsupervised Learning}} of {{Hierarchical Representations}}},
  isbn = {978-1-60558-516-1},
  url = {http://doi.acm.org/10.1145/1553374.1553453},
  doi = {10.1145/1553374.1553453},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  series = {ICML '09},
  publisher = {{ACM}},
  date = {2009},
  pages = {609--616},
  author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
  numpages = {8},
  acmid = {1553453},
  journal = {Proceedings of the 26th Annual International Conference on Machine Learning},
  year = {2009}
}

@article{SrivastavaDropoutSimpleWay2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  volume = {15},
  url = {http://jmlr.org/papers/v15/srivastava14a.html},
  journaltitle = {Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  date = {2014},
  pages = {1929--1958},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal = {Journal of Machine Learning Research},
  year = {2014}
}

@inproceedings{NguyenSynthesizingpreferredinputs2016a,
  title = {Synthesizing the Preferred Inputs for Neurons in Neural Networks via Deep Generator Networks},
  url = {http://lmb.informatik.uni-freiburg.de/Publications/2016/DB16d},
  booktitle = {Advances in {{Neural Information Processing Systems}} ({{NIPS}})},
  date = {2016},
  author = {Nguyen, A. and Dosovitskiy, A. and Yosinski, J. and Brox, T. and Clune, J.},
  journal = {Advances in Neural Information Processing Systems (NIPS)},
  year = {2016}
}

@inproceedings{RibeiroWhyShouldTrust2016,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  booktitle = {Knowledge {{Discovery}} and {{Data Mining}} ({{KDD}})},
  date = {2016},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  journal = {Knowledge Discovery and Data Mining (KDD)},
  year = {2016}
}


