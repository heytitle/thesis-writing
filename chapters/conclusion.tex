\chapter{Conclusion}
\label{cha:chapter5}
%\section{Summary}
We have provided extensive experiments towards explaining RNN decisions. Our experiments are artificially designed such that qualitative and quantitative evaluations can be done accordingly.  The results demonstrates that the architecture of RNN has considerably impact on the quality of explanation. More precisely, we found that deeper architecture and employing gating units significantly improve the explainability. 


Moreover, the level of  influence from the architecture configuration is different for each explanation technique. Based on our quantitative evaluations, deep Taylor decomposition and Layer-Wise Relevance Propagation(LRP) are more influenced by the architecture than sensitivity analysis(SA) and guided backprop(GB).  Training configuration is also another influential factor that could affect quality of explantation. In particular, for a certain setting, training with stationary dropout shows slight improvement on visual quality although the impact is not captured by our quantitative measurements.

More importantly, it is worth noting that we consider ConvR-LSTM-SD as the most explainable architecture in this thesis. In particular, we achieve decent explanation heatmaps when explaining it via $\lrpp$ without negative relevance considered. As a reminder, this result is shown on \addfigure{\ref{fig:heatmap_msc_convrlstm_pos_rel}}.

Lastly, we would like to further argue that the quality of RNN explanation need to be considered into 2 aspects, namely local  and global aspect. Noting that, they are different what described in Section \ref{sec:global_local_explanation}. The local aspect describes whether explanation of each input from a sequence is sound. In case of image related applications, it is already shown in literatures that this aspect can be improved by employing convolutional and pooling layer. Our ConvDeep experiments confirms this in RNN setting. On the other hand, the global aspect tells us whether RNN can properly propagate relevance quantities to the right inputs in a sequence. Our experiments strongly suggest that gating units are the key to improve the quality of explanation in this aspect. Therefore, RNN need to satisfy these 2 aspects in order to establish great explainability.

%
%DDDUnlike regular neural network, the quality of RNN explanation need to be considered into 2 aspects, namely local and global aspect. Noting that these aspects are different from Section . The informative aspect describes whether explanation of each input sound. In case of image related applications, this can be improved by employing convolutional and pooling layer. On the other hand, the global aspect tells us whether RNN can properly propagate relevance quantities to the right inputs. Local explanation can not have good quality if RNN lacks capability in the global aspect.




\section{Challenges}
We have encountered several challenges while working on the thesis. The first challenge is about evaluations. In particular, it is quite challenging to evaluate the quality of explanations when we do not have ground truth information available. This challenge led us to artificially construct the sequence and majority sample sequence classification problem to mitigate the problem.  Secondly, we have also experienced that initialization scheme of weights and biases is also another factor that could affect the quality of explanations although it would not affect the objective performance. We took $1/\sqrt{|\boldsymbol{a}|}$ initialization scheme as granted.


Lastly, because we were rely on only basic frameworks, such as TensorFlow, and implemented most of the code ourselves, we have found that implementing neural network systems is more challenging than traditional software development in a sense that we do not have a good way to properly verify the correctness of the code. Given the reason, we found that conservation property is extremely useful because it allows us to write unit tests that automatically verify the implementation during the development. This helped us faster validated related implementations as well as making sure that there will not be any systematic mistake in the integral part of the implementation of LRP and DTD explanation in further development.

%hyper parameters... 

\section{Future work}
Despite extensive results from our experiments, we still consider our experimental setting somewhat limited. Hence, one of future work would be to generalize and apply our work to broader setting. In particular,  applying the experiments on more diverge dataset and sequence length could be the first extension. Because of popularity of RNN in NLP domain, problems in this direction, such as text classification or sentiment analysis, are definitely worth experimenting. 

As discussed earlier that quantifying quality of explanation from RNN is challenging in several aspects, we believe establishing a better quantitative evaluation methodology is another possible study that should be done.

%because we do not have any reliable measurement to measure local quality corresponding to each input. This leads to inconsistent results between qualitative and quantitative evaluation. Hence, another possible study could be evaluation methodology for quantifying explanation heatmaps.
%
%ConsequeTntly, some of our quantitative results were slight different from what we have seen from comparison of actual explanation heatmaps. 
%
%
%Another possible study is about evaluation methodology for quantifying explanation heatmaps. In particular, we found that quantifying RNN explanation is challening because we do not have any reliable measurement to measure local quality corresponding to each input. Hence, some of our quantitative results were slight different from what we have seen from comparison of actual explanation heatmaps. 
%
%% We found that cosine similarity is somewhat limited because it is computed from global explanation 
%%
%%discards local information in explanation heatmap, hence the score is do  the quality of  could not capture whether local expalanation is good.
%%
%% study.